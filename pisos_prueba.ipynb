{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e520117b",
   "metadata": {},
   "source": [
    "### PENDIENTE\n",
    "### Cambiar csv por el enlace \n",
    "### Comentar cada paso (argumentando lo que hacemos)\n",
    "### Precio total o precio por metro cuadrado - cual es el mejor para el proyecto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb74d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba5e9ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar el archivo CSV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/datasets/thedevastator/prices-characteristics-of-spanish-homes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Mostrar las primeras filas para inspeccionar el dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Mario\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Mario\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Mario\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Mario\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('https://www.kaggle.com/datasets/thedevastator/prices-characteristics-of-spanish-homes')\n",
    "\n",
    "# Mostrar las primeras filas para inspeccionar el dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información general del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas innecesarias\n",
    "df.drop(columns=['Unnamed: 0', 'description', 'photo', 'Num Photos', 'recomendado'], inplace=True)\n",
    "\n",
    "# Quitar símbolos \"€ y m²\" en 'price' y 'size' y convertir a numérico\n",
    "df['price'] = pd.to_numeric(df['price'].str.replace('€', '').str.replace(',', ''), errors='coerce')\n",
    "df['size'] = pd.to_numeric(df['size'].str.replace('m²', '').str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Inspeccionar cambios\n",
    "df[['price', 'size']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "df = df.dropna(subset=['price', 'size', 'rooms', 'bathrooms', 'location', 'region', 'price/m2'])\n",
    "\n",
    "# Verificar si todavía quedan valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4f23d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas 'rooms' y 'bathrooms' a formato numérico\n",
    "df['rooms'] = pd.to_numeric(df['rooms'], errors='coerce')\n",
    "df['bathrooms'] = pd.to_numeric(df['bathrooms'], errors='coerce')\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['size'] = pd.to_numeric(df['size'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dee028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener valores únicos en la columna 'type'\n",
    "unique_types = df['type'].unique()\n",
    "\n",
    "# Imprimir los valores únicos\n",
    "print(\"Valores únicos en 'type':\")\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d65031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar 'piso' por 'pisos' en la columna 'type'\n",
    "df['type'] = df['type'].replace('piso', 'pisos')\n",
    "\n",
    "# Verificar los cambios\n",
    "print(df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5b33d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear términos de interacción\n",
    "df['size_rooms_interaction'] = df['size'] * df['rooms']\n",
    "df['size_bathrooms_interaction'] = df['size'] * df['bathrooms']\n",
    "df['rooms_bathrooms_interaction'] = df['rooms'] * df['bathrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuartiles\n",
    "Q1 = df['size'].quantile(0.25)\n",
    "Q3 = df['size'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir límites para detectar valores atípicos\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar los valores atípicos\n",
    "outliers = df[(df['size'] < lower_bound) | (df['size'] > upper_bound)]\n",
    "\n",
    "print(f\"Número de valores atípicos en 'size': {outliers.shape[0]}\")\n",
    "print(outliers[['size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c23d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuartiles para la columna 'rooms'\n",
    "Q1_rooms = df['rooms'].quantile(0.25)\n",
    "Q3_rooms = df['rooms'].quantile(0.75)\n",
    "IQR_rooms = Q3_rooms - Q1_rooms\n",
    "\n",
    "# Definir límites para detectar valores atípicos\n",
    "lower_bound_rooms = Q1_rooms - 1.5 * IQR_rooms\n",
    "upper_bound_rooms = Q3_rooms + 1.5 * IQR_rooms\n",
    "\n",
    "# Filtrar los valores atípicos\n",
    "outliers_rooms = df[(df['rooms'] < lower_bound_rooms) | (df['rooms'] > upper_bound_rooms)]\n",
    "\n",
    "print(f\"Número de valores atípicos en 'rooms': {outliers_rooms.shape[0]}\")\n",
    "print(outliers_rooms[['rooms']].head(10))  # Mostrar los primeros 10 valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc993c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuartiles para la columna 'bathrooms'\n",
    "Q1_bathrooms = df['bathrooms'].quantile(0.25)\n",
    "Q3_bathrooms = df['bathrooms'].quantile(0.75)\n",
    "IQR_bathrooms = Q3_bathrooms - Q1_bathrooms\n",
    "\n",
    "# Definir límites para detectar valores atípicos\n",
    "lower_bound_bathrooms = Q1_bathrooms - 1.5 * IQR_bathrooms\n",
    "upper_bound_bathrooms = Q3_bathrooms + 1.5 * IQR_bathrooms\n",
    "\n",
    "# Filtrar los valores atípicos\n",
    "outliers_bathrooms = df[(df['bathrooms'] < lower_bound_bathrooms) | (df['bathrooms'] > upper_bound_bathrooms)]\n",
    "\n",
    "print(f\"Número de valores atípicos en 'bathrooms': {outliers_bathrooms.shape[0]}\")\n",
    "print(outliers_bathrooms[['bathrooms']].head(10))  # Mostrar los primeros 10 valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "6ac9f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para eliminar los valores atípicos en 'size', 'rooms', y 'bathrooms'\n",
    "df_cleaned_final = df[\n",
    "    (df['size'] >= lower_bound) & (df['size'] <= upper_bound) &\n",
    "    (df['rooms'] >= lower_bound_rooms) & (df['rooms'] <= upper_bound_rooms) &\n",
    "    (df['bathrooms'] >= lower_bound_bathrooms) & (df['bathrooms'] <= upper_bound_bathrooms)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b12651",
   "metadata": {},
   "source": [
    "### Perform Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60056944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características (features) y variable objetivo (target)\n",
    "X = df_cleaned_final[['size', 'rooms', 'bathrooms', 'type', 'region', \n",
    "                       'size_rooms_interaction', 'size_bathrooms_interaction', 'rooms_bathrooms_interaction']]\n",
    "y = df_cleaned_final['price']  # La variable objetivo\n",
    "\n",
    "# Preprocesar características categóricas y escalar numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['size', 'rooms', 'bathrooms', \n",
    "                                    'size_rooms_interaction', \n",
    "                                    'size_bathrooms_interaction', \n",
    "                                    'rooms_bathrooms_interaction']),  \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['type', 'region'])  \n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "# Crear un pipeline que primero preprocesa y luego ajusta el modelo\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error cuadrático medio (MSE): {mse:.2f}\")\n",
    "print(f\"R² score del modelo en el conjunto de prueba: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441c692",
   "metadata": {},
   "source": [
    "### Model Selection / In this exercise we will be using KNN as our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características (features) y variable objetivo (target)\n",
    "X = df_cleaned_final[['size', 'rooms', 'bathrooms', 'type', 'region', \n",
    "                       'size_rooms_interaction', 'size_bathrooms_interaction', 'rooms_bathrooms_interaction']]\n",
    "y = df_cleaned_final['price']  # La variable objetivo\n",
    "\n",
    "# Preprocesar características categóricas y escalar numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['size', 'rooms', 'bathrooms', \n",
    "                                    'size_rooms_interaction', \n",
    "                                    'size_bathrooms_interaction', \n",
    "                                    'rooms_bathrooms_interaction']),  \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['type', 'region'])  \n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "# Crear el modelo KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Crear un pipeline que primero preprocesa y luego ajusta el modelo\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', knn_model)\n",
    "])\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error cuadrático medio (MSE) con KNN: {mse:.2f}\")\n",
    "print(f\"R² score del modelo en el conjunto de prueba: {r2:.4f}\")\n",
    "\n",
    "# Optimización de hiperparámetros con GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 7, 10, 15],  # Número de vecinos\n",
    "    'regressor__weights': ['uniform', 'distance'],  # Peso de los vecinos\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones con el mejor modelo\n",
    "y_pred_best = best_knn_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del mejor modelo\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Error cuadrático medio (MSE) con KNN optimizado: {mse_best:.2f}\")\n",
    "print(f\"R² score del modelo en el conjunto de prueba: {r2_best:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
